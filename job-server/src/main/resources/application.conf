# Settings for safe local mode development
spark {
  master = "local[4]"
  # spark web UI port
  webUrlPort = 8080

  jobserver {
    port = 8090

    # Number of job results to keep per JobResultActor/context
    job-result-cache-size = 5000

    jobdao = spark.jobserver.io.JobFileDAO

    filedao {
      rootdir = /tmp/spark-jobserver/filedao/data
    }

    # Time out for job server to wait while creating contexts
    context-creation-timeout = 15 s

    # A zero-arg class implementing spark.jobserver.util.SparkContextFactory
    context-factory = spark.jobserver.util.DefaultSparkContextFactory
  }

  # predefined Spark contexts
  # Below is an example, but do not uncomment it.   Everything defined here is carried over to
  # deploy-time configs, so they will be created in all environments.  :(
  contexts {
    # abc-demo {
    #   num-cpu-cores = 4            # Number of cores to allocate.  Required.
    #   memory-per-node = 1024m      # Executor memory per node, -Xmx style eg 512m, 1G, etc.
    # }
    # define additional contexts here
  }

  # Default settings for ad hoc as well as manually created contexts
  # You can add any Spark config params here, for example, spark.mesos.coarse = true
  context-settings {
    num-cpu-cores = 4           # Number of cores to allocate.  Required.
    memory-per-node = 512m      # Executor memory per node, -Xmx style eg 512m, 1G, etc.
    # max-jobs-per-context = 4  # Max # of jobs to run at the same time
  }
}

akka {
  # Use SLF4J/logback for deployed environment logging
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = DEBUG
  # kamon.logreporter.LogReporter was added to verify that kamon monitor was working. Not necessary for production
  # extensions = ["kamon.metric.Metrics", "kamon.datadog.Datadog", "kamon.logreporter.LogReporter"]
  extensions = ["kamon.metric.Metrics", "kamon.datadog.Datadog"]
}

# check the reference.conf in spray-can/src/main/resources for all defined settings
spray.can.server {
  # uncomment the next line for making this an HTTPS example
  # ssl-encryption = on
  idle-timeout = 20 s
  request-timeout = 15 s
  pipelining-limit = 2 # for maximum performance (prevents StopReading / ResumeReading messages to the IOBridge)
  # Needed for HTTP/1.0 requests with missing Host headers
  default-host-header = "spray.io:8765"
}

kamon {
  # Default dispatcher for all Kamon components, unless a more specific one is configured.
  default-dispatcher = "akka.actor.default-dispatcher"
  log-reporter {
    # Enable system metrics
    # In order to not get a ClassNotFoundException, we must register the kamon-sytem-metrics module
    report-system-metrics = false
  }
  metrics {
    # Time interval for collecting all metrics and send the snapshots to all subscribed actors.
    tick-interval = 1 second
    # Time interval for recording values on all registered gauges.
    gauge-recording-interval = 100 milliseconds
    # Default size for the LongBuffer that gets allocated for metrics collection and merge. The
    # value should correspond to the highest number of different buckets with values that might
    # exist in a single histogram during a metrics collection. The default value of 33792 is a
    # very conservative value and its equal to the total number of buckets required to cover values
    # from 1 nanosecond to 1 hour with 0.1% precision (3 significant value digits). That means
    # that would need to have at least one measurement on every bucket of a single histogram to
    # fully utilize this buffer, which is *really* unlikely to ever happen. Since the buffer should
    # be allocated once and reused it shouldn't impose a memory footprint issue.
    default-collection-context-buffer-size = 33792
    # Disables a big error message that will be typically logged if your application wasn't started
    # with the -javaagent:/path-to-aspectj-weaver.jar option. If you are only using KamonStandalone
    # it might be ok for you to turn this error off.
    disable-aspectj-weaver-missing-error = false
    dispatchers {
      # Dispatcher for periodical gauge value recordings.
      gauge-recordings = ${kamon.default-dispatcher}
      # Dispatcher for subscriptions and metrics collection actors.
      metric-subscriptions = ${kamon.default-dispatcher}
    }
    filters = [
      {
        actor {
          includes = ["user/*", "user/worker-*"]
          excludes = [ "system/*" ]
        }
      },
      {
        router {
          includes = [ "*" ]
          excludes = [ "system/*", "user/IO-*" ]
        }
      },
      {
        trace {
          includes = [ "*" ]
          excludes = []
        }
      },
      {
        dispatcher {
          includes = [ "*" ]
          excludes = []
        }
      }
    ]
    precision {
      default-histogram-precision {
        highest-trackable-value = 3600000000000
        significant-value-digits = 2
      }
      default-min-max-counter-precision {
        refresh-interval = 100 milliseconds
        highest-trackable-value = 999999999
        significant-value-digits = 2
      }
      default-gauge-precision {
        refresh-interval = 100 milliseconds
        highest-trackable-value = 999999999
        significant-value-digits = 2
      }
      // default-counter-precision {
      //   # Doesn't make sense because it's a simple counter
      // }


      // actor, router, trace, and dispatcher are all entity-names
      // all metric-names are listed with the entity objects
      actor {
        processing-time = ${kamon.metrics.precision.default-histogram-precision}
        time-in-mailbox = ${kamon.metrics.precision.default-histogram-precision}
        mailbox-size = ${kamon.metrics.precision.default-min-max-counter-precision}
        # errors = ... is not necessary because it's a simple counter not a min-max counter
      }
      router {
        processing-time = ${kamon.metrics.precision.default-histogram-precision}
        time-in-mailbox = ${kamon.metrics.precision.default-histogram-precision}
        # errors = ... is not necessary because it's a simple counter not a min-max counter
      }
      trace {
        elapsed-time = ${kamon.metrics.precision.default-histogram-precision}
        segment = ${kamon.metrics.precision.default-histogram-precision}
      }
      dispatcher {
        maximum-pool-size {
          highest-trackable-value = 999999999
          significant-value-digits = 2
        }
        running-thread-count {
          highest-trackable-value = 999999999
          significant-value-digits = 2
        }
        queued-task-count {
          highest-trackable-value = 999999999
          significant-value-digits = 2
        }
        pool-size {
          highest-trackable-value = 999999999
          significant-value-digits = 2
        }
      }
    }
    datadog {
      # Hostname and port in which your Datadog is running. Remember that Datadog packets are sent using UDP and
      # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
      hostname = "127.0.0.1"
      port = 8125
      # Interval between metrics data flushes to Datadog. It's value must be equal or greater than the
      # kamon.metrics.tick-interval setting.
      flush-interval = 10 second
      # Max packet size for UDP metrics data sent to Datadog.
      max-packet-size = 1024 bytes
      # Subscription patterns used to select which metrics will be pushed to Datadog. Note that first, metrics
      # collection for your desired entities must be activated under the kamon.metrics.filters settings.
      includes {
        actor      =  [ "*" ]
        trace      =  [ "*" ]
        dispatcher =  [ "*" ]
        router     =  [ "*" ]
      }
      # Enable system metrics
      # In order to not get a ClassNotFoundException, we must register the kamon-sytem-metrics module
      report-system-metrics = false
      # Application prefix for all metrics pushed to Datadog. The default namespacing scheme for metrics follows
      # this pattern:
      #    application.entity-name.metric-name
      application-name = "kamon"
    }
  }
  trace {
    # If ask-pattern-tracing is enabled, a WARN level log message will be generated if a future generated by the `ask`
    # pattern fails with a `AskTimeoutException` and the log message will contain a stack trace captured at the moment
    # the future was created.
    ask-pattern-tracing = on
  }
  weaver {
    # AspectJ options supported by LTW
    # showWeaveInfo: show informational messages whenever the weaver touches a class file.
    # verbose: show informational messages about the weaving process.
    # debug: show a messages for each class passed to the weaver indicating whether it was woven, excluded or ignored.
    # showWarn: show warning messages about the weaving process.
    showWeaveInfo = on
    verbose = on
    debug = on
    showWarn = on
  }
}